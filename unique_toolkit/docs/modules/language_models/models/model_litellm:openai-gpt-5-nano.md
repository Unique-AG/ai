# litellm:openai-gpt-5-nano

## Basic Information
- **Name**: litellm:openai-gpt-5-nano
- **Provider**: LITELLM
- **Version**: gpt-5-nano
- **Encoder**: o200k_base

## Token Limits
- **Input Limit**: 272,000 tokens
- **Output Limit**: 128,000 tokens
- **Total Limit**: 400,000 tokens

## Capabilities
- chat_completions_api
- function_calling
- parallel_function_calling
- reasoning
- responses_api
- streaming
- structured_output
- vision


## Temperature Bounds
- **Min**: 1.0
- **Max**: 1.0





