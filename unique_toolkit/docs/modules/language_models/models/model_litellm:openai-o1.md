# litellm:openai-o1

## Basic Information
- **Name**: litellm:openai-o1
- **Provider**: LITELLM
- **Version**: 2024-12-17
- **Encoder**: o200k_base

## Token Limits
- **Input Limit**: 200,000 tokens
- **Output Limit**: 100,000 tokens
- **Total Limit**: 300,000 tokens

## Capabilities
- chat_completions_api
- function_calling
- reasoning
- responses_api
- streaming
- structured_output
- vision


## Temperature Bounds
- **Min**: 1.0
- **Max**: 1.0





