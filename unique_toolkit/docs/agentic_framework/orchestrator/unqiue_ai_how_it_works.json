[
  {
    "role": "system",
    "content": "# System \n\nYou are Unique AI a system based on large language models created by UniqueAI\n\n**Knowledge cutoff**: 2024-10-24\n**Current date**: Saturday September 06, 2025\n\nOver the course of the conversation, you adapt to the user's tone and preference.\nTry to match the user's vibe, tone, and generally how they are speaking. You want the conversation to feel natural.\nYou engage in authentic conversation by responding to the information provided, asking relevant questions, and showing genuine curiosity.\nIf natural, continue the conversation with casual conversation.\n\n# Execution limits\n**Max tools calls**: 5, Maximum number of tool calls that can be called per iteration, any tool calls beyond this limit will be ignored.\n\n# Tools\nYou can use the following tools to fullfill the tasks given by the user and to answer their questions. \nBe mindful of using them each of them requires time and the user will have to wait.\n\n## Internal Search\nYou can use the InternalSearch tool to access internal company documentations, including information on policies, procedures, benefits, groups, financial details, and specific individuals. If this tool can help answer your question, feel free to use it to search the internal knowledge base for more information. If possible always try to get information from the internal knowledge base with the InternalSearch tool before using other tools.\nUse cases for the Internal Knowledge Search are:\n- User asks to work with a document: Most likely the document is uploaded to the chat and mentioned in a message and can be loaded with this tool\n- Policy and Procedure Verification: Use the internal search tool to find the most current company policies, procedures, or guidelines to ensure compliance and accuracy in responses.\n- Project-Specific Information: When answering questions related to ongoing projects or initiatives, use the internal search to access project documents, reports, or meeting notes for precise details.\n- Employee Directory and Contact Information: Utilize the internal search to locate contact details or organizational charts to facilitate communication and collaboration within the company.\n- Confidential and Proprietary Information: When dealing with sensitive topics that require proprietary knowledge or confidential data, use the internal search to ensure the information is sourced from secure and authorized company documents.\n\n**Instruction Query Splitting**\nYou should split the user question into multiple search strings when the user's question needs to be decomposed / rewritten to find different facts. Perform for each search string an individual tool call. Avoid short queries that are extremely broad and will return unrelated results. Strip the search string of any extraneous details, e.g. instructions or unnecessary context. However, you must fill in relevant context from the rest of the conversation to make the question complete. E.g. \"What was their age?\" => \"What was Kevin's age?\" because the preceding conversation makes it clear that the user is talking about Kevin.\n\nHere are some examples of how to use the InternalSearch tool:\nUser: What was the GDP of France and Italy in the 1970s? => search strings: [\"france gdp 1970\", \"italy gdp 1970\"] # Splitting of the query into 2 queries and perform 2 tool calls\nUser: What does the report say about the GPT4 performance on MMLU? => search strings: [\"GPT4 performance on MMLU?\"] # Simplify the query\n\n## Web Search\nUse the `WebSearch` tool to access up-to-date information from the web or when responding to the user requires information about their location. Some examples of when to use the `WebSearch` tool include:\n- Local Information: Use the `WebSearch` tool to respond to questions that require information about the user's location, such as the weather, local businesses, or events.\n- Freshness: If up-to-date information on a topic could potentially change or enhance the answer, call the `WebSearch` tool any time you would otherwise refuse to answer a question because your knowledge might be out of date.\n- Niche Information: If the answer would benefit from detailed information not widely known or understood (which might be found on the internet), such as details about a small neighborhood, a less well-known company, or arcane regulations, use web sources directly rather than relying on the distilled knowledge from pretraining.\n- Accuracy: If the cost of a small mistake or outdated information is high (e.g., using an outdated version of a software library or not knowing the date of the next game for a sports team), then use the `WebSearch` tool.\n\n**Instruction Query Splitting**\nYou should split the user question into multiple queries when the user's question needs to be decomposed / rewritten to find different facts. Perform for each query an individual tool call. Avoid short queries that are extremely broad and will return unrelated results. Strip the search string of any extraneous details, e.g. instructions or unnecessary context. However, you must fill in relevant context from the rest of the conversation to make the question complete. E.g. \"What was their age?\" => \"What was Kevin's age?\" because the preceding conversation makes it clear that the user is talking about Kevin.\n\nHere are some examples of how to use the WebSearch tool:\nUser: What was the GDP of France and Italy in the 1970s? => queries: [\"france gdp 1970\", \"italy gdp 1970\"] # Splitting of the query into 2 queries and perform 2 tool calls\nUser: What does the report say about the GPT4 performance on MMLU? => queries: [\"GPT4 performance on MMLU?\"] # Simplify the query\n\n\n\n\n# Answer Style\n### 1. Use Markdown for Structure\n- Use ## for primary section headings and ### for subheadings.\n- Apply relevant emojis in headings to enhance friendliness and scannability (e.g., ## ðŸ“Œ Summary, ### ðŸš€ How It Works).\n- Favor a clean, logical outline â€” structure answers into well-separated sections.\n\n### 2. Text Styling\n- Use **bold** for key concepts, actionable terms, and labels.\n- Use *italics* for emphasis, definitions, side remarks, or nuance.\n- Use `inline code` for technical terms, file paths (/mnt/data/file.csv), commands (git clone), commands, values and parameters (--verbose)\n- Break long text blocks into shorter paragraphs for clarity and flow.\n\n### 3. Lists & Step Sequences\n- Use bullet lists - for unordered points.\n- Use numbered lists 1., 2. when describing ordered procedures or sequences.\n- Avoid walls of text â€” always format complex ideas into digestible segments.\n\n### 4. Tables & Visual Aids\n- Where applicable, use Markdown tables for structured comparisons, data summaries, and matrices.\n- When analyzing documents, incorporate insights from rendered images, diagrams, charts, and tables â€” cite their location (e.g., \"See chart on page 2\").\n\n### 5. Code\n- Use triple backticks <code>```</code> for multiline code blocks, scripts, or config examples.\n- Use single backticks ` for inline code or syntax references.\n\n### 6. Contextual Framing\n- Begin complex answers with a high-level summary or framing sentence.\n- Use phrases like \"Hereâ€™s a breakdown,\" \"Letâ€™s walk through,\" or \"Key insight:\" to guide the user.\n\n### 7. Naming Conventions\n- Prefer consistent section headers for common response types (e.g., Summary, Risks, Data, Steps).\n- Consider using emoji prefixes to visually differentiate types (ðŸ“Š Data, ðŸ’¡ Insights, ðŸ“Ž Sources).\n\n### 8. Data Timestamping\n- When presenting data from documents, always include the relevant date or period.\n- Format examples: \"As of Q1 2024\", \"Based on data from February 28, 2025\"\n"
  },
  {
    "role": "user",
    "content": "OK, so in the following part I will.I want to describe a piece of code.Actually, this time it's an orchestrator.And that orchestrator has.Yeah, it's an orchestra, an AI orchestrator. So I'm an agent, An agent.This agent we I will also paste some.I will put the code in, you will see the code and additionally what we want to do is in the end we should have a documentation about what this agent does and it should be logically.Following each other.You need to create it in a type of in. Best would be in markdown that we have a block of markdown that I could copy and and and build.It needs to include the code or everything. Makes sense to include the code in the in the in the documentation as this might help the readability of the actual class.Umm please, I will describe it more or less function by function. So then try to also put the full function in at that point.Here we go.So this agent, how it starts is that it receives from in the in the constructor it receives the event that the users been sending. So in this event it's a typical typical event that comes in. It contains the user's message and all the information of how to stream back to the front end. Additionally, it receives a configuration. The configuration is the setup of the whole agent that is directly passed from the.To this.In the web call, what happens is the configuration is taken from what has been set up for each space. So that is the configuration that comes from the space.Now additionally, we are also setting some of these some of the the managers, the managers.Will be described in a later in a later stage.OK, let's start.Good. So we do have the run method. The run method is the first method that is to be executed. What happens here is it first checks has there already been something streamed to the front end? So we're checking whether there is already something there. Else we put, we are starting the agenda and that's actually what it does now it starts to do so it does the loop for the Max iterations. Why do we need the Max iterations? We need the Max iterations that.This agent comes to a stop so that it doesn't repeatedly, repeatedly, repeatedly try to call up the.The tools that it has been given.Then it will.Plan or execute and in the plan or execute, I will go into this below. The planner execute will retrieve sort of the plan that the agent makes up so that the LLM makes up. What has to be done right? Which tools have to be executed or do we have to stream? Does it have to be streamed already?So when he comes in here it then also has when it once it's done with the potentially for \nstreaming, it will also have references on the message. So it will add to the references that already have been found to the manager.Actually, these are the references.To the manager. To the reference manager.Then it starts the. It also updates the thinking manager if there is anything to to update. Thinking managers are used for thinking models or to give the user more information on what happens in that step.Then we process the plan, the plan that has been done above, which are these loop messages. This is an array of messages that goes to the to the.T to the LLM it.So then it processes.The Plant.In the process of the the the the the process of the plan can be like execute tools or.Finish or start streaming or do a follow up. Create a post processing.Or do an evaluation of the generated message.That that can happen there.What can also happen is that the tools are executed. So should tools be executed then for sure it is not the last round we need to do with the model. Then it will go on and have in this execute a false so it's not going to exit the loop.The thinking manager.So should we exit the loop? We of course have to tell the thinking manager that sort of it has to close, so that it has to close the steps and then basically the loop is over because a message has been streamed, the user has received the message from the LM. That also means no more tool calls needed to be done.Now let's say we're in the last second to last iteration, or in the last iteration, and we wish that there should actually. So this should actually never happen because the the tool should come to an end before it's the before it's the last message.Therefore we inform the user, hey, something went wrong.That there were too many iterations.We would do.Then we would do.A start.The thinking manager would then need to be informed hey this is not the last loop so a new message to come in. So we update these messages so the new thinking steps are could be displayed.Then we check if we need to create a new message. We would do that if the message has streamed tools so that some tools are executed and it also streamed the message. So we are.Creating a new message and then we repeat the loop and it starts from the beginning.At some point all the all the tools are executed, the message is streamed and we will exit this loop.\nNext we will explain what the plan or execute does. Remember the planner execute is happening at the very beginning of the loop. To understand what has to be done next, do we need to use a tool? Do we need to put some tools in it? So if you plan that process right, So how does it do that from from that? So from the user it will receive information about which tools have to be.Force tools are tools that the user wants that they for sure being executed. So it could be that case that there is some force tools in, but it could also be that there is in the end where in the last iteration and we don't want to add more, we don't want that the last iteration can actually execute tools. So we removed tools to hand it over to the model that it's not even able to call any of the tools we we are giving.An option.At the very end.We within the normal case. In the standard case, no tools are forced. It is not the last iteration, so it is just the default case. In the default case we do.Give it all the tools that are available, the model and we give it all the history that it that was that was created up to now. So that means have there been any other tools already executed or or what have you?Right. So then it would stream to the front end and it would return us this stream response, which is the information that is needed sort of what has to be happening next. So do we have to call tools or whatever?So that is the plan or execute the beginning of the plan or execute we go and grab.The latest update of.The compose.Plan that the composed plan is basically the the history including the the.System message and the user message that might have to be refined by by this by the agent. So the system message.The system prompt it's not the system message to system prompt.And it can be modified. How it can be modified? You can read below in the render system prompt and the render user prompt.So in the plan or execute we do have the messages available at the very beginning.Then when we process the plan, what could have happened? There are three possibilities, so one could be.That there is an emty message. So something went wrong, Something is weird.But so there is no tool calls and there is no St. message. But it could also be that there is only two calls. So if there is only two calls to be executed, we handle those two calls. So if there is 2 calls, they have to be executed and this is being handed over to the handle to call function which then will hand it over to the tools manager to execute all the tools.If there is no two call, there is no two calls. It means it's a message. The message that is that the plan has to be processed is basically streamed. So it's streamed and answered and now we have to potentially post process that stream with different steps.Now let's go to the handle 2 course functionality. The handle 2 course is basically.Appending all the tool calls to the history, because we have received like which tools have to be called. So if we receive those, but now we need to tell it to the history, which of these tools are actually to be to be saved in. In the all these two calls have to be saved in the history. Then we execute all these two calls. That means we retrieve back a response depending on the response they contain information about.References or it could contain information about.How to call what was the result of the of the two call like the?Yeah, all the information.The two call what they would look like. We go into another part of the documentation, then we manage the reference. So in these two calls, as I said, there could be references, so we're going to extract those references. There could also be debug info in debug information that we wish to attach to the message. So we would add this as well and we would add eventually also.Like now that all the tools have been called and executed, we also added two responses to it so that we have the information for the next round available.That it can potentially do something with this information of what these tools have done for it.Then we check whether one of these two course has actually taken control. So what that could mean is, for example in a deep research, the deep research would take full control of the stream. So the base agent here would stop and not do anything anymore, but it would execute only it would let other agents basically execute it. So the tools would then be agents that would execute this.Good.Now let's come to the history construction.The history construct.This is actually called compose message plan execution. That's the construction of the history. So how do we do this? So first we are getting the user message.But then we're also rendering the system prompt, the user prompt, and the system prompt. So what does it do when we render these prompts? Let's go with the system prompt first. In the system prompt, you want to maybe modify the full system prompt by. So the agent wishes to modify the full system prompt. He wants to modify it by giving it some more information which tools are available, how they need to be used? Have they been already?Executed and would we need to give information of how these tools?Are how they the two response are to be formatted in the message?This is what we would do next.This will be rendered using ginger templates. The templates will be attached below for this prompt. For the user prompt, it's the same thing. Maybe there has to be something rendered in the user prompt Would be attached at the very end. For example, what would be coming in would be information coming from the.Coming from MCP, for example, MCP server information that this part would need to be put into the, into the into the template.Good, that's it. Next up is the code.\n\nfrom datetime import datetime\nfrom logging import Logger\n\nimport jinja2\nfrom unique_toolkit.app.schemas import ChatEvent, McpServer\nfrom unique_toolkit.chat.service import ChatService\nfrom unique_toolkit.content.service import ContentService\nfrom unique_toolkit.agentic.debug_info_manager.debug_info_manager import (\n    DebugInfoManager,\n)\nfrom unique_toolkit.agentic.evaluation.evaluation_manager import EvaluationManager\nfrom  unique_toolkit.agentic.history_manager.history_manager import HistoryManager\nfrom unique_toolkit.language_model.schemas import (\n    LanguageModelAssistantMessage,\n    LanguageModelMessages,\n    LanguageModelStreamResponse,\n)\nfrom unique_toolkit.agentic.postprocessor.postprocessor_manager import (\n    PostprocessorManager,\n)\nfrom unique_toolkit.agentic.reference_manager.reference_manager import ReferenceManager\nfrom unique_toolkit.agentic.thinking_manager.thinking_manager import ThinkingManager\nfrom unique_toolkit.agentic.tools.tool_manager import ToolManager\n\nfrom unique_ai_v2.config import UniqueAIConfig\n\nEMPTY_MESSAGE_WARNING = (\n    \"âš ï¸ **The language model was unable to produce an output.**\\n\"\n    \"It did not generate any content or perform a tool call in response to your request. \"\n    \"This is a limitation of the language model itself.\\n\\n\"\n    \"**Please try adapting or simplifying your prompt.** \"\n    \"Rewording your input can often help the model respond successfully.\"\n)\n\n\nclass UniqueAI:\n    start_text = \"\"\n    current_iteration_index = 0\n\n    def __init__(\n        self,\n        logger: Logger,\n        event: ChatEvent,\n        config: UniqueAIConfig,\n        chat_service: ChatService,\n        content_service: ContentService,\n        debug_info_manager: DebugInfoManager,\n        reference_manager: ReferenceManager,\n        thinking_manager: ThinkingManager,\n        tool_manager: ToolManager,\n        history_manager: HistoryManager,\n        evaluation_manager: EvaluationManager,\n        postprocessor_manager: PostprocessorManager,\n        mcp_servers: list[McpServer],\n    ):\n        self._logger = logger\n        self._event = event\n        self._config = config\n        self._chat_service = chat_service\n        self._content_service = content_service\n\n        self._debug_info_manager = debug_info_manager\n        self._reference_manager = reference_manager\n        self._thinking_manager = thinking_manager\n        self._tool_manager = tool_manager\n\n        self._history_manager = history_manager\n\n        self._evaluation_manager = evaluation_manager\n        self._postprocessor_manager = postprocessor_manager\n        self._latest_assistant_id: str = event.payload.assistant_message.id\n        self._mcp_servers = mcp_servers\n\n    ############################################################\n    # Override of base methods\n    ############################################################\n    # @track(name=\"loop_agent_run\")  # Group traces together\n    async def run(self):\n        \"\"\"\n        Main loop of the agent. The agent will iterate through the loop, runs the plan and\n        processes tool calls if any are returned.\n        \"\"\"\n        self._logger.info(\"Start LoopAgent...\")\n\n        if self._history_manager.has_no_loop_messages():  # TODO: why do we even need to check its always no loop messages on this when its called.\n            self._chat_service.modify_assistant_message(\n                content=\"Starting agentic loop...\"  # TODO: this must be more informative\n            )\n\n        ## Loop iteration\n        for i in range(self._config.agent.max_loop_iterations):\n            self.current_iteration_index = i\n            self._logger.info(f\"Starting iteration {i + 1}...\")\n\n            # Plan execution\n            loop_response = await self._plan_or_execute()\n            self._logger.info(\"Done with _plan_or_execute\")\n\n            self._reference_manager.add_references(\n                loop_response.message.references\n            )\n            self._logger.info(\"Done with adding references\")\n\n            # Update tool progress reporter\n            self._thinking_manager.update_tool_progress_reporter(loop_response)\n\n            # Execute the plan\n            exit_loop = await self._process_plan(loop_response)\n            self._logger.info(\"Done with _process_plan\")\n\n            if exit_loop:\n                self._thinking_manager.close_thinking_steps(loop_response)\n                self._logger.info(\"Exiting loop.\")\n                break\n\n            if i == self._config.agent.max_loop_iterations - 1:\n                self._logger.error(\"Max iterations reached.\")\n                await self._chat_service.modify_assistant_message_async(\n                    content=\"I have reached the maximum number of self-reflection iterations. Please clarify your request and try again...\",\n                )\n                break\n\n            self.start_text = self._thinking_manager.update_start_text(\n                self.start_text, loop_response\n            )\n            await self._create_new_assistant_message_if_loop_response_contains_content(\n                loop_response\n            )\n\n        await self._chat_service.modify_assistant_message_async(\n            set_completed_at=True,\n        )\n\n    # @track()\n    async def _plan_or_execute(self) -> LanguageModelStreamResponse:\n        self._logger.info(\"Planning or executing the loop.\")\n        messages = await self._compose_message_plan_execution()\n\n        self._logger.info(\"Done composing message plan execution.\")\n\n        # Forces tool calls only in first iteration\n        if (\n            len(self._tool_manager.get_forced_tools()) > 0\n            and self.current_iteration_index == 0\n        ):\n            self._logger.info(\"Its needs forced tool calls.\")\n            self._logger.info(\n                f\"Forced tools: {self._tool_manager.get_forced_tools()}\"\n            )\n            responses = [\n                await self._chat_service.complete_with_references_async(\n                    messages=messages,\n                    model_name=self._config.space.language_model.name,\n                    tools=self._tool_manager.get_tool_definitions(),\n                    content_chunks=self._reference_manager.get_chunks(),\n                    start_text=self.start_text,\n                    debug_info=self._debug_info_manager.get(),\n                    temperature=self._config.agent.experimental.temperature,\n                    other_options=self._config.agent.experimental.additional_llm_options\n                    | {\"toolChoice\": opt},\n                )\n                for opt in self._tool_manager.get_forced_tools()\n            ]\n\n            # Merge responses and refs:\n            tool_calls = []\n            references = []\n            for r in responses:\n                if r.tool_calls:\n                    tool_calls.extend(r.tool_calls)\n                references.extend(r.message.references)\n\n            stream_response = responses[0]\n            stream_response.tool_calls = (\n                tool_calls if len(tool_calls) > 0 else None\n            )\n            stream_response.message.references = references\n        elif (\n            self.current_iteration_index\n            == self._config.agent.max_loop_iterations - 1\n        ):\n            self._logger.info(\n                \"we are in the last iteration we need to produce an answer now\"\n            )\n            # No tool calls in last iteration\n            stream_response = await self._chat_service.complete_with_references_async(\n                messages=messages,\n                model_name=self._config.space.language_model.name,\n                content_chunks=self._reference_manager.get_chunks(),\n                start_text=self.start_text,\n                debug_info=self._debug_info_manager.get(),\n                temperature=self._config.agent.experimental.temperature,\n                other_options=self._config.agent.experimental.additional_llm_options,\n            )\n\n        else:\n            self._logger.info(\n                f\"we are in the iteration {self.current_iteration_index} asking the model to tell if we should use tools or if it will just stream\"\n            )\n            stream_response = await self._chat_service.complete_with_references_async(\n                messages=messages,\n                model_name=self._config.space.language_model.name,\n                tools=self._tool_manager.get_tool_definitions(),\n                content_chunks=self._reference_manager.get_chunks(),\n                start_text=self.start_text,\n                debug_info=self._debug_info_manager.get(),\n                temperature=self._config.agent.experimental.temperature,\n                other_options=self._config.agent.experimental.additional_llm_options,\n            )\n\n        return stream_response\n\n    async def _process_plan(\n        self, loop_response: LanguageModelStreamResponse\n    ) -> bool:\n        self._logger.info(\n            \"Processing the plan, executing the tools and checking for loop exit conditions once all is done.\"\n        )\n\n        if loop_response.is_empty():\n            self._logger.debug(\"Empty model response, exiting loop.\")\n            self._chat_service.modify_assistant_message(\n                content=EMPTY_MESSAGE_WARNING\n            )\n            return True\n\n        call_tools = len(loop_response.tool_calls or []) > 0\n        if call_tools:\n            self._logger.debug(\n                \"Tools were called we process them and do not exit the loop\"\n            )\n\n            return await self._handle_tool_calls(loop_response)\n\n        self._logger.debug(\"No tool calls. we might exit the loop\")\n\n        return await self._handle_no_tool_calls(loop_response)\n\n    async def _compose_message_plan_execution(self) -> LanguageModelMessages:\n        original_user_message = self._event.payload.user_message.text\n        rendered_user_message_string = await self._render_user_prompt()\n        rendered_system_message_string = await self._render_system_prompt()\n\n        messages = await self._history_manager.get_history_for_model_call(\n            original_user_message,\n            rendered_user_message_string,\n            rendered_system_message_string,\n            self._postprocessor_manager.remove_from_text,\n        )\n        return messages\n\n    async def _render_user_prompt(self) -> str:\n        user_message_template = jinja2.Template(\n            self._config.agent.prompt_config.user_message_prompt_template\n        )\n\n        tool_descriptions_with_user_prompts = [\n            prompts.tool_user_prompt\n            for prompts in self._tool_manager.get_tool_prompts()\n        ]\n\n        used_tools = [m.name for m in self._tool_manager.get_tools()]\n\n        mcp_server_user_prompts = [\n            mcp_server.user_prompt for mcp_server in self._mcp_servers\n        ]\n\n        tool_descriptions = self._tool_manager.get_tool_prompts()\n\n        query = self._event.payload.user_message.text\n\n        user_msg = user_message_template.render(\n            query=query,\n            tool_descriptions=tool_descriptions,\n            used_tools=used_tools,\n            mcp_server_user_prompts=list(mcp_server_user_prompts),\n            tool_descriptions_with_user_prompts=tool_descriptions_with_user_prompts,\n        )\n        return user_msg\n\n    async def _render_system_prompt(\n        self,\n    ) -> str:\n        # TODO: Collect tool information here and adapt to system prompt\n        tool_descriptions = self._tool_manager.get_tool_prompts()\n\n        used_tools = [m.name for m in self._tool_manager.get_tools()]\n\n        system_prompt_template = jinja2.Template(\n            self._config.agent.prompt_config.system_prompt_template\n        )\n\n        date_string = datetime.now().strftime(\"%A %B %d, %Y\")\n\n        mcp_server_system_prompts = [\n            mcp_server.system_prompt for mcp_server in self._mcp_servers\n        ]\n\n        system_message = system_prompt_template.render(\n            model_info=self._config.space.language_model.model_dump(\n                mode=\"json\"\n            ),\n            date_string=date_string,\n            tool_descriptions=tool_descriptions,\n            used_tools=used_tools,\n            project_name=self._config.space.project_name,\n            custom_instructions=self._config.space.custom_instructions,\n            max_tools_per_iteration=self._config.agent.experimental.loop_configuration.max_tool_calls_per_iteration,\n            max_loop_iterations=self._config.agent.max_loop_iterations,\n            current_iteration=self.current_iteration_index + 1,\n            mcp_server_system_prompts=mcp_server_system_prompts,\n        )\n        return system_message\n\n    async def _handle_no_tool_calls(\n        self, loop_response: LanguageModelStreamResponse\n    ) -> bool:\n        \"\"\"Handle the case where no tool calls are returned.\"\"\"\n        selected_evaluation_names = (\n            self._tool_manager.get_evaluation_check_list()\n        )\n        evaluation_results = await self._evaluation_manager.run_evaluations(\n            selected_evaluation_names, loop_response, self._latest_assistant_id\n        )\n\n        await self._postprocessor_manager.run_postprocessors(loop_response)\n\n        if not all(result.is_positive for result in evaluation_results):\n            self._logger.warning(\n                \"we should add here the retry counter add an instruction and retry the loop for now we just exit the loop\"\n            )  # TODO: add retry counter and instruction\n\n        return True\n\n    async def _handle_tool_calls(\n        self, loop_response: LanguageModelStreamResponse\n    ) -> bool:\n        \"\"\"Handle the case where tool calls are returned.\"\"\"\n        self._logger.info(\"Processing tool calls\")\n\n        tool_calls = loop_response.tool_calls or []\n\n        # Append function call to history\n        self._history_manager._append_tool_calls_to_history(tool_calls)\n\n        # Execute tool calls\n        tool_call_responses = await self._tool_manager.execute_selected_tools(\n            tool_calls\n        )\n\n        # Process results with error handling\n        self._reference_manager.extract_referenceable_chunks(\n            tool_call_responses\n        )\n        self._debug_info_manager.extract_tool_debug_info(tool_call_responses)\n        self._history_manager.add_tool_call_results(tool_call_responses)\n\n        return self._tool_manager.does_a_tool_take_control(tool_calls)\n\n    async def _create_new_assistant_message_if_loop_response_contains_content(\n        self, loop_response: LanguageModelStreamResponse\n    ) -> None:\n        if self._thinking_manager.thinking_is_displayed():\n            return\n        if not loop_response.message.text:\n            return\n\n        # if anything sets the start text the model did not produce content.\n        # So we need to remove that text from the message.\n        message_text_without_start_text = loop_response.message.text.replace(\n            self.start_text.strip(), \"\"\n        ).strip()\n        if message_text_without_start_text == \"\":\n            return\n\n        ###\n        # ToDo: Once references on existing assistant messages can be deleted, we will switch from creating a new assistant message to modifying the existing one (with previous references deleted)\n        ###\n        new_assistant_message = (\n            await self._chat_service.create_assistant_message_async(content=\"\")\n        )\n\n        # the new message must have an id that is valid else we use the old one\n        self._latest_assistant_id = (\n            new_assistant_message.id or self._latest_assistant_id\n        )\n\n        self._history_manager.add_assistant_message(\n            LanguageModelAssistantMessage(\n                content=loop_response.message.original_text or \"\",\n            )\n        )\n\n\njinja templates\n\nthe system prompt:\n```\n{#- System Prompt Section -#}\n# System \n\nYou are Unique AI a system based on large language models created by UniqueAI\n\n**Knowledge cutoff**: {{ model_info.info_cutoff_at | default('unknown') }}\n**Current date**: {{ date_string }}\n\nOver the course of the conversation, you adapt to the user's tone and preference.\nTry to match the user's vibe, tone, and generally how they are speaking. You want the conversation to feel natural.\nYou engage in authentic conversation by responding to the information provided, asking relevant questions, and showing genuine curiosity.\nIf natural, continue the conversation with casual conversation.\n\n\n# Execution limits\n**Max tools calls**: {{ max_tools_per_iteration }}, Maximum number of tool calls that can be called per iteration, any tool calls beyond this limit will be ignored.\n\n{# Tools Section -#}\n{%- if tool_descriptions and tool_descriptions|length > 0 -%}\n\n# Tools\nYou can use the following tools to fullfill the tasks given by the user and to answer their questions. \nBe mindful of using them each of them requires time and the user will have to wait.\n\n{% for tool_description in tool_descriptions -%}\n{#- The tool name and description should always be available -#}\n## {{ tool_description.name }}\nThis tool is called {{ tool_description.display_name }} by the user.\n\n{{ tool_description.tool_description}} \n\n{%- if tool_description.tool_system_prompt and tool_description.tool_system_prompt|length > 0 %}\n\n### Tool-Specific Instructions\n{{ tool_description.tool_system_prompt }}\n{%- endif %}\n\n{# Include formatting guidelines if result handling instructions are available and the tool is used -#}\n{%- if tool_description.tool_format_information_for_system_prompt and tool_description.tool_format_information_for_system_prompt|length > 0 and tool_description.name in used_tools -%}\n### Formatting guidelines for output of {{ tool_description.name}}\n{{ tool_description.tool_format_information_for_system_prompt }}\n{%- endif -%}\n{%- endfor -%}\n{%- endif %}\n\n{# Answer Style Section #}\n# Answer Style\n### 1. Use Markdown for Structure\n- Use ## for primary section headings and ### for subheadings.\n- Apply relevant emojis in headings to enhance friendliness and scannability (e.g., ## ðŸ“Œ Summary, ### ðŸš€ How It Works).\n- Favor a clean, logical outline â€” structure answers into well-separated sections.\n\n### 2. Text Styling\n- Use **bold** for key concepts, actionable terms, and labels.\n- Use *italics* for emphasis, definitions, side remarks, or nuance.\n- Use `inline code` for technical terms, file paths (/mnt/data/file.csv), commands (git clone), commands, values and parameters (--verbose)\n- Break long text blocks into shorter paragraphs for clarity and flow.\n\n### 3. Lists & Step Sequences\n- Use bullet lists - for unordered points.\n- Use numbered lists 1., 2. when describing ordered procedures or sequences.\n- Avoid walls of text â€” always format complex ideas into digestible segments.\n\n### 4. Tables & Visual Aids\n- Where applicable, use Markdown tables for structured comparisons, data summaries, and matrices.\n- When analyzing documents, incorporate insights from rendered images, diagrams, charts, and tables â€” cite their location (e.g., \"See chart on page 2\").\n\n### 5. Code\n- Use triple backticks <code>```</code> for multiline code blocks, scripts, or config examples.\n- Use single backticks ` for inline code or syntax references.\n\n### 6. Contextual Framing\n- Begin complex answers with a high-level summary or framing sentence.\n- Use phrases like \"Hereâ€™s a breakdown,\" \"Letâ€™s walk through,\" or \"Key insight:\" to guide the user.\n\n### 7. Naming Conventions\n- Prefer consistent section headers for common response types (e.g., Summary, Risks, Data, Steps).\n- Consider using emoji prefixes to visually differentiate types (ðŸ“Š Data, ðŸ’¡ Insights, ðŸ“Ž Sources).\n\n### 8. Data Timestamping\n- When presenting data from documents, always include the relevant date or period.\n- Format examples: \"As of Q1 2024\", \"Based on data from February 28, 2025\"\n\n### 9. Formula Rendering\n- Please identify formulas and return them in latex format\n- Ensure to identify and wrap all formulas between \\, [, ...formula... , \\, ]. Eg. `\\[E = mc^2\\]`\n\n{#- MCP System Prompts Section #}\n{%- if mcp_server_system_prompts and mcp_server_system_prompts|length > 0 %}\n\n# MCP Server Instructions\n\n{%- for server_prompt in mcp_server_system_prompts %}\n\n{{ server_prompt }}\n{%- endfor %}\n{%- endif -%}\n\n{#- Custom instructions #}\n{% if custom_instructions and custom_instructions|length > 0 %}\n# SYSTEM INSTRUCTIONS CONTEXT\nYou are operating in the context of a wider project called {{ project_name | default('Unique AI') }}.\nThis project uses custom instructions, capabilities and data to optimize Unique AI\nfor a more narrow set of tasks.\n\nHere are instructions from the user outlining how you should respond:\n\n{{ custom_instructions }}\n{%- endif %}\n````\n\n\nuser message:"
  }
]